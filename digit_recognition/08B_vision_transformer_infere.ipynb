{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"},{"sourceId":105455,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":88371,"modelId":112600}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import ViTForImageClassification\nimport torch\nfrom torch import nn, optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\n\nimport pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-09-01T14:34:37.931736Z","iopub.execute_input":"2024-09-01T14:34:37.932579Z","iopub.status.idle":"2024-09-01T14:34:37.937889Z","shell.execute_reply.started":"2024-09-01T14:34:37.932533Z","shell.execute_reply":"2024-09-01T14:34:37.936898Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-01T14:39:45.232540Z","iopub.execute_input":"2024-09-01T14:39:45.232982Z","iopub.status.idle":"2024-09-01T14:39:47.278949Z","shell.execute_reply.started":"2024-09-01T14:39:45.232944Z","shell.execute_reply":"2024-09-01T14:39:47.278058Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X_test = torch.tensor(test_df.values, dtype=torch.float32) / 255.0\nX_test = X_test.view(-1, 1, 28, 28)\nX_test = X_test.repeat(1, 3, 1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T14:39:47.280599Z","iopub.execute_input":"2024-09-01T14:39:47.280938Z","iopub.status.idle":"2024-09-01T14:39:47.479353Z","shell.execute_reply.started":"2024-09-01T14:39:47.280903Z","shell.execute_reply":"2024-09-01T14:39:47.478526Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:07:50.456030Z","iopub.execute_input":"2024-09-01T15:07:50.456934Z","iopub.status.idle":"2024-09-01T15:07:50.462000Z","shell.execute_reply.started":"2024-09-01T15:07:50.456885Z","shell.execute_reply":"2024-09-01T15:07:50.460895Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, images, transform=None):\n        self.images = images\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:07:51.272035Z","iopub.execute_input":"2024-09-01T15:07:51.272458Z","iopub.status.idle":"2024-09-01T15:07:51.278476Z","shell.execute_reply.started":"2024-09-01T15:07:51.272418Z","shell.execute_reply":"2024-09-01T15:07:51.277526Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"test_dataset = MNISTDataset(X_test, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:07:51.805703Z","iopub.execute_input":"2024-09-01T15:07:51.806446Z","iopub.status.idle":"2024-09-01T15:07:51.811081Z","shell.execute_reply.started":"2024-09-01T15:07:51.806406Z","shell.execute_reply":"2024-09-01T15:07:51.810149Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"model = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224\", num_labels=10, ignore_mismatched_sizes=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/vit-for-mnist/transformers/default/1/fine_tuned_vit_mnist.pth\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:07:52.919531Z","iopub.execute_input":"2024-09-01T15:07:52.920187Z","iopub.status.idle":"2024-09-01T15:07:52.929871Z","shell.execute_reply.started":"2024-09-01T15:07:52.920149Z","shell.execute_reply":"2024-09-01T15:07:52.928912Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"ViTForImageClassification(\n  (vit): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTSdpaAttention(\n            (attention): ViTSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  )\n  (classifier): Linear(in_features=768, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n\nall_predictions = []\n\nwith torch.no_grad():\n    for inputs in test_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs).logits\n        _, predictions = torch.max(outputs, 1)\n        all_predictions.append(predictions.cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:09:33.462162Z","iopub.execute_input":"2024-09-01T15:09:33.462572Z","iopub.status.idle":"2024-09-01T15:12:44.700104Z","shell.execute_reply.started":"2024-09-01T15:09:33.462535Z","shell.execute_reply":"2024-09-01T15:12:44.699015Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"all_predictions = np.concatenate(all_predictions)\npredictions_list = all_predictions.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:12:44.701988Z","iopub.execute_input":"2024-09-01T15:12:44.702314Z","iopub.status.idle":"2024-09-01T15:12:44.708575Z","shell.execute_reply.started":"2024-09-01T15:12:44.702280Z","shell.execute_reply":"2024-09-01T15:12:44.707696Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(predictions_list)\nsubmission.index.name='ImageId'\nsubmission.index+=1\nsubmission.columns=['Label']","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:12:44.709773Z","iopub.execute_input":"2024-09-01T15:12:44.710162Z","iopub.status.idle":"2024-09-01T15:12:44.729434Z","shell.execute_reply.started":"2024-09-01T15:12:44.710121Z","shell.execute_reply":"2024-09-01T15:12:44.728579Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=\"ImageId\")","metadata":{"execution":{"iopub.status.busy":"2024-09-01T15:12:44.731301Z","iopub.execute_input":"2024-09-01T15:12:44.731602Z","iopub.status.idle":"2024-09-01T15:12:44.776777Z","shell.execute_reply.started":"2024-09-01T15:12:44.731567Z","shell.execute_reply":"2024-09-01T15:12:44.776037Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}